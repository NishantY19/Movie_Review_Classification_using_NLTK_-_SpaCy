{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport re\nimport string\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-24T09:53:23.071644Z","iopub.execute_input":"2022-08-24T09:53:23.072022Z","iopub.status.idle":"2022-08-24T09:53:23.873812Z","shell.execute_reply.started":"2022-08-24T09:53:23.071986Z","shell.execute_reply":"2022-08-24T09:53:23.872603Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration and Processing","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndata.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:53:39.807839Z","iopub.execute_input":"2022-08-24T09:53:39.808364Z","iopub.status.idle":"2022-08-24T09:53:41.257229Z","shell.execute_reply.started":"2022-08-24T09:53:39.808327Z","shell.execute_reply":"2022-08-24T09:53:41.256079Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:53:44.418999Z","iopub.execute_input":"2022-08-24T09:53:44.419567Z","iopub.status.idle":"2022-08-24T09:53:44.427551Z","shell.execute_reply.started":"2022-08-24T09:53:44.419528Z","shell.execute_reply":"2022-08-24T09:53:44.426632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,6))\nplt.title(\"Data Distribution\")\nsns.countplot(x = \"sentiment\", data = data)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:53:46.940241Z","iopub.execute_input":"2022-08-24T09:53:46.940826Z","iopub.status.idle":"2022-08-24T09:53:47.140909Z","shell.execute_reply.started":"2022-08-24T09:53:46.940779Z","shell.execute_reply":"2022-08-24T09:53:47.139785Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data['lenght'] = data['review'].apply(lambda x : len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:53:50.420819Z","iopub.execute_input":"2022-08-24T09:53:50.421203Z","iopub.status.idle":"2022-08-24T09:53:51.097454Z","shell.execute_reply.started":"2022-08-24T09:53:50.421168Z","shell.execute_reply":"2022-08-24T09:53:51.096249Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,6))\nplt.title(\"Text lenght\")\n\nsns.histplot(x=\"lenght\", data = data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:53:54.916554Z","iopub.execute_input":"2022-08-24T09:53:54.916981Z","iopub.status.idle":"2022-08-24T09:53:55.738654Z","shell.execute_reply.started":"2022-08-24T09:53:54.916942Z","shell.execute_reply":"2022-08-24T09:53:55.737604Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (14,8))\nax1 = fig.add_subplot(121)\nplt.title(\"Positive text lenght\")\nsns.histplot(x=\"lenght\", data = data[data['sentiment'] == 'positive'], ax=ax1)\n\nax2 = fig.add_subplot(122)\nplt.title(\"Negative text lenght\")\nsns.histplot(x=\"lenght\", data = data[data['sentiment'] == 'negative'], ax=ax2)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:54:00.622958Z","iopub.execute_input":"2022-08-24T09:54:00.623354Z","iopub.status.idle":"2022-08-24T09:54:01.637947Z","shell.execute_reply.started":"2022-08-24T09:54:00.623319Z","shell.execute_reply":"2022-08-24T09:54:01.636824Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Example\ndata.iloc[1,0]","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:54:05.531646Z","iopub.execute_input":"2022-08-24T09:54:05.532047Z","iopub.status.idle":"2022-08-24T09:54:05.539449Z","shell.execute_reply.started":"2022-08-24T09:54:05.532002Z","shell.execute_reply":"2022-08-24T09:54:05.538151Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def clean_review(text):\n    clean_text = re.sub('<br\\s?\\/>|<br>', '', text) \n    clean_text = re.sub('[^a-zA-Z\\']', ' ', clean_text)\n    clean_text = clean_text.lower()\n    return clean_text","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:54:41.274268Z","iopub.execute_input":"2022-08-24T09:54:41.274812Z","iopub.status.idle":"2022-08-24T09:54:41.279719Z","shell.execute_reply.started":"2022-08-24T09:54:41.274776Z","shell.execute_reply":"2022-08-24T09:54:41.278782Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data['review'] = data['review'].apply(lambda x : clean_review(x))\ndata.iloc[1,0]","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:54:44.500076Z","iopub.execute_input":"2022-08-24T09:54:44.500618Z","iopub.status.idle":"2022-08-24T09:54:47.989838Z","shell.execute_reply.started":"2022-08-24T09:54:44.500580Z","shell.execute_reply":"2022-08-24T09:54:47.988802Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Modelling\n### Bag Of Words","metadata":{}},{"cell_type":"code","source":"# Splitting the data into train set and validation set\ntrain_data = data[:30000]\nval_data = data[30000:]","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:55:32.514695Z","iopub.execute_input":"2022-08-24T09:55:32.515443Z","iopub.status.idle":"2022-08-24T09:55:32.521320Z","shell.execute_reply.started":"2022-08-24T09:55:32.515389Z","shell.execute_reply":"2022-08-24T09:55:32.520252Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"For efficient processing we will disable some pipline component like parser and named entity recognition","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# Create an empty model\nnlp = spacy.blank(\"en\")\n\n# Create custom TextCategorizer with exclusive classes and bag of words architecture\ntextcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)\nprint(nlp.pipe_names)\ntextcat.add_label(\"positive\")\ntextcat.add_label(\"negative\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:56:01.848033Z","iopub.execute_input":"2022-08-24T09:56:01.848450Z","iopub.status.idle":"2022-08-24T09:56:02.910839Z","shell.execute_reply.started":"2022-08-24T09:56:01.848410Z","shell.execute_reply":"2022-08-24T09:56:02.909546Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Data Preparation\ntrain_texts = train_data['review'].values\ntrain_labels = [{'cats': {'positive': label == 'positive','negative': label == 'negative'}} \n                for label in train_data['sentiment']]","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:56:14.794992Z","iopub.execute_input":"2022-08-24T09:56:14.795390Z","iopub.status.idle":"2022-08-24T09:56:14.966043Z","shell.execute_reply.started":"2022-08-24T09:56:14.795353Z","shell.execute_reply":"2022-08-24T09:56:14.964926Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from spacy.util import minibatch\nimport random\n\ndef model_train(model, train, optimizer):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train)\n    \n    batches = minibatch(train, size=8)\n    for batch in batches:\n        texts, labels = zip(*batch)\n        model.update(texts, labels, sgd=optimizer, losses=losses)\n        \n    return losses","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:56:22.339081Z","iopub.execute_input":"2022-08-24T09:56:22.339476Z","iopub.status.idle":"2022-08-24T09:56:22.345508Z","shell.execute_reply.started":"2022-08-24T09:56:22.339437Z","shell.execute_reply":"2022-08-24T09:56:22.344369Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# 1st Iteration\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\noptimizer = nlp.begin_training()\ntrain = list(zip(train_texts, train_labels))\nlosses = model_train(nlp, train, optimizer)\nprint(losses['textcat'])","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:56:47.802922Z","iopub.execute_input":"2022-08-24T09:56:47.803333Z","iopub.status.idle":"2022-08-24T09:58:50.100916Z","shell.execute_reply.started":"2022-08-24T09:56:47.803296Z","shell.execute_reply":"2022-08-24T09:58:50.099798Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Prediction:","metadata":{}},{"cell_type":"code","source":"data.iloc[30001,:2]","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:59:08.082366Z","iopub.execute_input":"2022-08-24T09:59:08.082756Z","iopub.status.idle":"2022-08-24T09:59:08.090797Z","shell.execute_reply.started":"2022-08-24T09:59:08.082720Z","shell.execute_reply":"2022-08-24T09:59:08.089813Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"doc = nlp(data.iloc[30001,0])\nprint(doc.cats)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:59:25.738404Z","iopub.execute_input":"2022-08-24T09:59:25.738814Z","iopub.status.idle":"2022-08-24T09:59:25.746259Z","shell.execute_reply.started":"2022-08-24T09:59:25.738773Z","shell.execute_reply":"2022-08-24T09:59:25.744906Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Predict list of reviews\ndef predict(nlp, texts): \n\n    docs = [nlp.tokenizer(text) for text in texts]    \n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe('textcat')\n    predicted_class = textcat.predict(docs)[0].argmin(axis=1)\n    \n    return predicted_class","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:59:29.741615Z","iopub.execute_input":"2022-08-24T09:59:29.742222Z","iopub.status.idle":"2022-08-24T09:59:29.746876Z","shell.execute_reply.started":"2022-08-24T09:59:29.742169Z","shell.execute_reply":"2022-08-24T09:59:29.745987Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data.iloc[30001:30004,:2]","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:59:35.002948Z","iopub.execute_input":"2022-08-24T09:59:35.003619Z","iopub.status.idle":"2022-08-24T09:59:35.015242Z","shell.execute_reply.started":"2022-08-24T09:59:35.003568Z","shell.execute_reply":"2022-08-24T09:59:35.014156Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Negative review -> 0; positive review -> 1\npredict(nlp, list(data.iloc[30001:30004,0].values))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:59:38.567192Z","iopub.execute_input":"2022-08-24T09:59:38.567586Z","iopub.status.idle":"2022-08-24T09:59:38.576564Z","shell.execute_reply.started":"2022-08-24T09:59:38.567546Z","shell.execute_reply":"2022-08-24T09:59:38.575818Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nmapper = {'positive':1, 'negative':0}\nval_data['sentiment'] = val_data['sentiment'].apply(lambda x : mapper[x])\nval_data.sentiment.values","metadata":{"execution":{"iopub.status.busy":"2022-08-24T09:59:41.321551Z","iopub.execute_input":"2022-08-24T09:59:41.322222Z","iopub.status.idle":"2022-08-24T09:59:41.520616Z","shell.execute_reply.started":"2022-08-24T09:59:41.322177Z","shell.execute_reply":"2022-08-24T09:59:41.519718Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, texts, labels): \n    predicted_class = predict(model, texts)\n    accuracy = accuracy_score(predicted_class, labels)\n    fscore = f1_score(predicted_class, labels)\n    return accuracy, fscore","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:00:05.164257Z","iopub.execute_input":"2022-08-24T10:00:05.164667Z","iopub.status.idle":"2022-08-24T10:00:05.170092Z","shell.execute_reply.started":"2022-08-24T10:00:05.164633Z","shell.execute_reply":"2022-08-24T10:00:05.168859Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"accuracy, f1score = evaluate(nlp, list(val_data.review.values), val_data.sentiment.values)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1_score: {f1score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:00:09.824199Z","iopub.execute_input":"2022-08-24T10:00:09.824597Z","iopub.status.idle":"2022-08-24T10:00:29.529482Z","shell.execute_reply.started":"2022-08-24T10:00:09.824556Z","shell.execute_reply":"2022-08-24T10:00:29.528672Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Model Training \nn_iters = 6\nfor i in range(n_iters):\n    losses = model_train(nlp, train, optimizer)\n    accuracy, f1score = evaluate(nlp, list(val_data.review.values), val_data.sentiment.values)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f} \\t F1_Score: {f1score:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:00:33.051815Z","iopub.execute_input":"2022-08-24T10:00:33.052497Z","iopub.status.idle":"2022-08-24T10:15:41.359432Z","shell.execute_reply.started":"2022-08-24T10:00:33.052449Z","shell.execute_reply":"2022-08-24T10:15:41.358345Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nstp = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:19:00.032962Z","iopub.execute_input":"2022-08-24T10:19:00.033418Z","iopub.status.idle":"2022-08-24T10:19:00.842114Z","shell.execute_reply.started":"2022-08-24T10:19:00.033365Z","shell.execute_reply":"2022-08-24T10:19:00.841064Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"WordCloud of positive reviews, It is better to add some words to our stopwords set such as: movie, film, story ... because such words may appear in both positive and negative reviews.","metadata":{}},{"cell_type":"code","source":"poswords = ' '.join([text for text in train_data[train_data['sentiment'] == 'positive']['review']])\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, stopwords=stp,\n                      background_color='white').generate(poswords)\n\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:19:37.948318Z","iopub.execute_input":"2022-08-24T10:19:37.948688Z","iopub.status.idle":"2022-08-24T10:19:52.330477Z","shell.execute_reply.started":"2022-08-24T10:19:37.948654Z","shell.execute_reply":"2022-08-24T10:19:52.329390Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"del nlp, textcat, optimizer","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:20:00.562676Z","iopub.execute_input":"2022-08-24T10:20:00.563107Z","iopub.status.idle":"2022-08-24T10:20:00.572322Z","shell.execute_reply.started":"2022-08-24T10:20:00.563067Z","shell.execute_reply":"2022-08-24T10:20:00.571162Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.blank(\"en\")\n\n# Create custom TextCategorizer with exclusive classes and cnn architecture\ntextcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\nnlp.add_pipe(textcat)\nprint(nlp.pipe_names)\ntextcat.add_label(\"positive\")\ntextcat.add_label(\"negative\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:20:10.923501Z","iopub.execute_input":"2022-08-24T10:20:10.924242Z","iopub.status.idle":"2022-08-24T10:20:11.156442Z","shell.execute_reply.started":"2022-08-24T10:20:10.924199Z","shell.execute_reply":"2022-08-24T10:20:11.155128Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Train a CNN architecture needs many resources (RAM), I will use a small subset of data.","metadata":{}},{"cell_type":"code","source":"def load_data(data):\n    # Splitting the data into train set and validation set\n    train_data = data[:10000]\n    val_data = data[10000:13000]\n    mapper = {'positive':1, 'negative':0}\n    val_data['sentiment'] = val_data['sentiment'].apply(lambda x : mapper[x])\n    train_texts = train_data['review'].values\n    train_labels = [{'cats': {'positive': label == 'positive','negative': label == 'negative'}} \n                for label in train_data['sentiment']]\n    return list(zip(train_texts, train_labels)), list(val_data.review.values), val_data.sentiment.values","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:20:15.282906Z","iopub.execute_input":"2022-08-24T10:20:15.283296Z","iopub.status.idle":"2022-08-24T10:20:15.290143Z","shell.execute_reply.started":"2022-08-24T10:20:15.283261Z","shell.execute_reply":"2022-08-24T10:20:15.288840Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"n_iters = 1\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\noptimizer = nlp.begin_training()\ntrain, valrev, valsnt = load_data(data)\nfor i in range(n_iters):\n    losses = model_train(nlp, train, optimizer)\n    accuracy, f1score = evaluate(nlp, valrev, valsnt)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f} \\t F1_Score: {f1score:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T10:20:33.310714Z","iopub.execute_input":"2022-08-24T10:20:33.311109Z","iopub.status.idle":"2022-08-24T10:24:23.478686Z","shell.execute_reply.started":"2022-08-24T10:20:33.311073Z","shell.execute_reply":"2022-08-24T10:24:23.477400Z"},"trusted":true},"execution_count":36,"outputs":[]}]}